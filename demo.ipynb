{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from fourlang.text_to_4lang import TextTo4lang\n",
    "from fourlang.lexicon import Lexicon\n",
    "from graphviz import Source\n",
    "from scripts.parse_data import read, read_sherliic, build_graph\n",
    "from scripts.similarity import Similarity\n",
    "\n",
    "from tqdm import tqdm\n",
    "preds = []\n",
    "text_to_4lang = TextTo4lang(lang=\"en\")\n",
    "sherlic_data = read_sherliic(\"data/dev.csv\", ud_path=\"data/relation_index.tsv\", keep_context=True)\n",
    "sherlic_data_frame = build_graph(sherlic_data)\n",
    "\n",
    "lexicon = Lexicon(lang=\"en\")\n",
    "\n",
    "similarity = Similarity(with_embedding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semeval_data_frame = read(\"en\", graded=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sherlic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clear_node(node):\n",
    "    \"\"\"\n",
    "    Clears the node from the 4lang id parts\n",
    "    :param node: the text to clear\n",
    "    :return: the cleared text\n",
    "    \"\"\"\n",
    "    return re.sub(r'_[0-9][0-9]*', '', node.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def asim_jac_edges(graph_premise, graph_hypothesis):\n",
    "    \"\"\"\n",
    "    Asymmetric Jaccard similarity between the edges of the definition graphs\n",
    "    :param graph_premise: the definition graph of the premise\n",
    "    :param graph_hypothesis: the definition graph of the hypothesis\n",
    "    :return: the ratio of overlapping edges per the length of the hypothesis definition\n",
    "    \"\"\"\n",
    "    prem = set([(clear_node(s), clear_node(r), e['color'])\n",
    "                for (s, r, e) in graph_premise.G.edges(data=True)])\n",
    "    hyp = set([(clear_node(s), clear_node(r), e['color'])\n",
    "               for (s, r, e) in graph_hypothesis.G.edges(data=True)])\n",
    "    \n",
    "    hyp_cleared = []\n",
    "    for triplet in hyp:\n",
    "        if triplet[0] != \"a\" and  triplet[0] != \"b\" and triplet[1] != \"a\" and triplet[1] != \"b\":\n",
    "            hyp_cleared.append(triplet)\n",
    "            \n",
    "    hyp = set(hyp_cleared)\n",
    "    sim = hyp & prem\n",
    "    if not sim or len(hyp) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        #return float(len(sim)) / math.sqrt(len(hyp))\n",
    "        #return len(sim)\n",
    "        return float(len(sim)) / len(hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise = text_to_4lang.process_text(\"saxophone\", method=\"expand\", depth=3, blacklist=[\"in\", \"of\", \"on\"])\n",
    "premise.filter_graph(\"part\")\n",
    "dot_graph_premise = premise.to_dot()\n",
    "Source(dot_graph_premise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_4lang.get_definition(\"mole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sherlic_data.iloc[105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "67,68,72,75,76,95,105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_premise = text_to_4lang.process_deps(sherlic_data_frame.iloc[67].premise, method=\"expand\", depth=1, blacklist=[\"in\", \"on\", \"of\"])\n",
    "graph_hypothesis = text_to_4lang.process_deps(sherlic_data_frame.iloc[67].hypothesis, method=\"expand\", depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_graph_premise = graph_premise.to_dot()\n",
    "Source(dot_graph_premise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_graph_premise = graph_hypothesis.to_dot()\n",
    "Source(dot_graph_premise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise = text_to_4lang.process_text(\"educate\", method=\"expand\", depth=1)\n",
    "dot_graph_premise = premise.to_dot()\n",
    "Source(dot_graph_premise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanfordnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = stanfordnlp.Pipeline() # This sets up a default neural pipeline in English\n",
    "doc = nlp(\"A material that may be used as food.\")\n",
    "doc.sentences[0].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda20617c17c43741ba8ba4c4fe663d3782"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
